{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 1 Homework\n",
    "\n",
    "## Docker & SQL\n",
    "\n",
    "In this homework we'll prepare the environment \n",
    "and practice with Docker and SQL\n",
    "\n",
    "## Question 1. Knowing docker tags\n",
    "\n",
    "Run the command to get information on Docker \n",
    "\n",
    "```docker --help```\n",
    "\n",
    "Now run the command to get help on the \"docker build\" command:\n",
    "\n",
    "```docker build --help```\n",
    "\n",
    "Do the same for \"docker run\".\n",
    "\n",
    "Which tag has the following text? - *Automatically remove the container when it exits* \n",
    "\n",
    "- `--delete`\n",
    "- `--rc`\n",
    "- `--rmc`\n",
    "- `--rm`\n",
    "\n",
    "### Answer :: `--rm`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2. Understanding docker first run \n",
    "\n",
    "Run docker with the python:3.9 image in an interactive mode and the entrypoint of bash.\n",
    "Now check the python modules that are installed ( use ```pip list``` ). \n",
    "\n",
    "What is version of the package *wheel* ?\n",
    "\n",
    "- 0.42.0\n",
    "- 1.0.0\n",
    "- 23.0.1\n",
    "- 58.1.0\n",
    "\n",
    "![](https://i.imgur.com/vTrrdF8.png)\n",
    "\n",
    "### Answer :: `0.42.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Postgres\n",
    "\n",
    "Run Postgres and load data as shown in the videos\n",
    "We'll use the green taxi trips from September 2019:\n",
    "\n",
    "```wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-09.csv.gz```\n",
    "\n",
    "**Answer => ::**\n",
    "\n",
    "```shell\n",
    "python \\\n",
    "    ./01-wk01-intro-plus-prerequi/src/01_pipeline_nyc_taxi_tripdata_to_localdb.py \\\n",
    "    --data-source \"${PWD}/00-test-intermediate-artifacts/green_tripdata_2019-09.csv.gz\" \\\n",
    "    --db-table-name green_tripdata_2019_09\n",
    "```\n",
    "\n",
    "![](https://i.imgur.com/EtfcUom.png)\n",
    "\n",
    "![](https://i.imgur.com/fsLp6k6.png)\n",
    "\n",
    "You will also need the dataset with zones:\n",
    "\n",
    "```wget https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv```\n",
    "\n",
    "Download this data and put it into Postgres (with jupyter notebooks or with a pipeline)\n",
    "\n",
    "**Answer => ::**\n",
    "\n",
    "```shell\n",
    "python \\\n",
    "    ./01-wk01-intro-plus-prerequi/src/02_pipeline_nyc_taxi_zone_lookup_to_localdb.py \\\n",
    "    --data-source \"${PWD}/00-test-intermediate-artifacts/taxi+_zone_lookup.csv\" \\\n",
    "    --db-table-name taxi_plus_zone_lookup\n",
    "```\n",
    "\n",
    "![](https://i.imgur.com/u0ncRdd.png)\n",
    "\n",
    "![](https://i.imgur.com/Sr9mAKf.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure you have `sqlalchemy` and `pandas` installed in your environment. If not, you can install them using pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in /home/popoyi/dscbox/sun/rack200-01-dataengg/600-01-bcamps-zoomcamp/003-01-pydev/lib/python3.10/site-packages (2.0.25)\n",
      "Requirement already satisfied: pandas in /home/popoyi/dscbox/sun/rack200-01-dataengg/600-01-bcamps-zoomcamp/003-01-pydev/lib/python3.10/site-packages (2.2.0)\n",
      "Requirement already satisfied: python-dotenv in /home/popoyi/dscbox/sun/rack200-01-dataengg/600-01-bcamps-zoomcamp/003-01-pydev/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/popoyi/dscbox/sun/rack200-01-dataengg/600-01-bcamps-zoomcamp/003-01-pydev/lib/python3.10/site-packages (from sqlalchemy) (4.9.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/popoyi/dscbox/sun/rack200-01-dataengg/600-01-bcamps-zoomcamp/003-01-pydev/lib/python3.10/site-packages (from sqlalchemy) (3.0.3)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /home/popoyi/dscbox/sun/rack200-01-dataengg/600-01-bcamps-zoomcamp/003-01-pydev/lib/python3.10/site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/popoyi/dscbox/sun/rack200-01-dataengg/600-01-bcamps-zoomcamp/003-01-pydev/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/popoyi/dscbox/sun/rack200-01-dataengg/600-01-bcamps-zoomcamp/003-01-pydev/lib/python3.10/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/popoyi/dscbox/sun/rack200-01-dataengg/600-01-bcamps-zoomcamp/003-01-pydev/lib/python3.10/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/popoyi/dscbox/sun/rack200-01-dataengg/600-01-bcamps-zoomcamp/003-01-pydev/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sqlalchemy pandas python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve database URL and name from environment variables\n",
    "db_url = os.getenv('DATABASE_URL')\n",
    "db_name = os.getenv('DATABASE_NAME')\n",
    "db_uri_path = f\"{db_url}/{db_name}\"\n",
    "\n",
    "# Create a database connection\n",
    "db_conn = create_engine(db_uri_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3. Count records \n",
    "\n",
    "How many taxi trips were totally made on September 18th 2019?\n",
    "\n",
    "Tip: started and finished on 2019-09-18. \n",
    "\n",
    "Remember that `lpep_pickup_datetime` and `lpep_dropoff_datetime` columns are in the format timestamp (date and hour+min+sec) and not in date.\n",
    "\n",
    "- 15767\n",
    "- 15612\n",
    "- 15859\n",
    "- 89009\n",
    "\n",
    "### **Answer :: =>** `15612`\n",
    "\n",
    "```\n",
    "SELECT COUNT(*) AS total_trips\n",
    "FROM green_tripdata_2019_09\n",
    "WHERE \n",
    "    lpep_pickup_datetime >= '2019-09-18 00:00:00' AND \n",
    "    lpep_pickup_datetime < '2019-09-19 00:00:00' AND \n",
    "    lpep_dropoff_datetime >= '2019-09-18 00:00:00' AND \n",
    "    lpep_dropoff_datetime < '2019-09-19 00:00:00';\n",
    "```\n",
    "\n",
    "![](https://i.imgur.com/yOdovwv.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_trips\n",
      "0        15612\n"
     ]
    }
   ],
   "source": [
    "# SQL query\n",
    "sql_query = \"\"\"\n",
    "SELECT COUNT(*) AS total_trips\n",
    "FROM green_tripdata_2019_09\n",
    "WHERE \n",
    "    lpep_pickup_datetime >= '2019-09-18 00:00:00' AND \n",
    "    lpep_pickup_datetime < '2019-09-19 00:00:00' AND \n",
    "    lpep_dropoff_datetime >= '2019-09-18 00:00:00' AND \n",
    "    lpep_dropoff_datetime < '2019-09-19 00:00:00';\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and fetch the result into a DataFrame\n",
    "result_df = pd.read_sql_query(sql_query, db_conn)\n",
    "\n",
    "# Display the result\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4. Largest trip for each day\n",
    "\n",
    "Which was the pick up day with the largest trip distance\n",
    "Use the pick up time for your calculations.\n",
    "\n",
    "- 2019-09-18\n",
    "- 2019-09-16\n",
    "- 2019-09-26\n",
    "- 2019-09-21\n",
    "\n",
    "### **Answer ::** `2019-09-26`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pickup_day  max_trip_distance\n",
      "0  2019-09-26             341.64\n",
      "1  2019-09-21             135.53\n",
      "2  2019-09-16             114.30\n",
      "3  2019-09-28              89.64\n",
      "4  2019-09-24              82.12\n"
     ]
    }
   ],
   "source": [
    "# SQL query\n",
    "sql_query = \"\"\"\n",
    "SELECT \n",
    "    DATE(lpep_pickup_datetime) AS pickup_day,\n",
    "    MAX(trip_distance) AS max_trip_distance\n",
    "FROM \n",
    "    green_tripdata_2019_09\n",
    "GROUP BY \n",
    "    DATE(lpep_pickup_datetime)\n",
    "ORDER BY max_trip_distance DESC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and fetch the result into a DataFrame\n",
    "result_df = pd.read_sql_query(sql_query, db_conn)\n",
    "\n",
    "# Display the result\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5. The number of passengers\n",
    "\n",
    "Consider lpep_pickup_datetime in '2019-09-18' and ignoring Borough has Unknown\n",
    "\n",
    "Which were the 3 pick up Boroughs that had a sum of total_amount superior to 50000?\n",
    " \n",
    "- \"Brooklyn\" \"Manhattan\" \"Queens\"\n",
    "- \"Bronx\" \"Brooklyn\" \"Manhattan\"\n",
    "- \"Bronx\" \"Manhattan\" \"Queens\" \n",
    "- \"Brooklyn\" \"Queens\" \"Staten Island\"\n",
    "\n",
    "### **Answer :: =>** `\"Brooklyn\" \"Manhattan\" \"Queens\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     borough  total_revenue\n",
      "0   Brooklyn       96333.24\n",
      "1  Manhattan       92271.30\n",
      "2     Queens       78671.71\n"
     ]
    }
   ],
   "source": [
    "# SQL query\n",
    "sql_query = \"\"\"\n",
    "SELECT \n",
    "    tpzl.borough,\n",
    "    SUM(gt.total_amount) AS total_revenue\n",
    "FROM \n",
    "    green_tripdata_2019_09 AS gt\n",
    "JOIN \n",
    "    taxi_plus_zone_lookup AS tpzl\n",
    "ON \n",
    "    gt.pulocationid = tpzl.locationid\n",
    "WHERE \n",
    "    DATE(gt.lpep_pickup_datetime) = '2019-09-18'\n",
    "    AND tpzl.borough <> 'Unknown'\n",
    "GROUP BY \n",
    "    tpzl.borough\n",
    "HAVING \n",
    "    SUM(gt.total_amount) > 50000\n",
    "ORDER BY \n",
    "    total_revenue DESC\n",
    "LIMIT 3;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and fetch the result into a DataFrame\n",
    "result_df = pd.read_sql_query(sql_query, db_conn)\n",
    "\n",
    "# Display the result\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6. Largest tip\n",
    "\n",
    "For the passengers picked up in September 2019 in the zone name Astoria which was the drop off zone that had the largest tip?\n",
    "We want the name of the zone, not the id.\n",
    "\n",
    "Note: it's not a typo, it's `tip` , not `trip`\n",
    "\n",
    "- Central Park\n",
    "- Jamaica\n",
    "- JFK Airport\n",
    "- Long Island City/Queens Plaza\n",
    "\n",
    "### **Answer :: =>** `JFK Airport`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  dropoff_zone_name  largest_tip\n",
      "0       JFK Airport        62.31\n",
      "1          Woodside        30.00\n",
      "2          Kips Bay        28.00\n"
     ]
    }
   ],
   "source": [
    "# SQL query\n",
    "sql_query = \"\"\"\n",
    "SELECT \n",
    "    dropoff_zone.zone AS dropoff_zone_name,\n",
    "    MAX(gtd.tip_amount) AS largest_tip\n",
    "FROM \n",
    "    green_tripdata_2019_09 gtd\n",
    "JOIN \n",
    "    taxi_plus_zone_lookup pickup_zone ON gtd.pulocationid = pickup_zone.locationid\n",
    "JOIN \n",
    "    taxi_plus_zone_lookup dropoff_zone ON gtd.dolocationid = dropoff_zone.locationid\n",
    "WHERE \n",
    "    pickup_zone.zone = 'Astoria'\n",
    "    AND DATE(gtd.lpep_pickup_datetime) >= '2019-09-01' \n",
    "    AND DATE(gtd.lpep_pickup_datetime) < '2019-10-01'\n",
    "GROUP BY \n",
    "    dropoff_zone_name\n",
    "ORDER BY \n",
    "    largest_tip DESC\n",
    "LIMIT 3;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and fetch the result into a DataFrame\n",
    "result_df = pd.read_sql_query(sql_query, db_conn)\n",
    "\n",
    "# Display the result\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terraform\n",
    "\n",
    "In this section homework we'll prepare the environment by creating resources in GCP with Terraform.\n",
    "\n",
    "In your VM on GCP/Laptop/GitHub Codespace install Terraform. \n",
    "Copy the files from the course repo\n",
    "[here](https://github.com/DataTalksClub/data-engineering-zoomcamp/tree/main/week_1_basics_n_setup/1_terraform_gcp/terraform) to your VM/Laptop/GitHub Codespace.\n",
    "\n",
    "Modify the files as necessary to create a GCP Bucket and Big Query Dataset.\n",
    "\n",
    "\n",
    "## Question 7. Creating Resources\n",
    "\n",
    "After updating the main.tf and variable.tf files run:\n",
    "\n",
    "```\n",
    "terraform apply\n",
    "```\n",
    "\n",
    "Paste the output of this command into the homework submission form.\n",
    "\n",
    "### **Answer :: =>**\n",
    "\n",
    "> `terraform plan`\n",
    "\n",
    "![](https://i.imgur.com/OczC07j.png)\n",
    "\n",
    "> `terraform apply`\n",
    "\n",
    "![](https://i.imgur.com/Yx8hTze.png)\n",
    "\n",
    "> `terraform destroy`\n",
    "\n",
    "![](https://i.imgur.com/l5rORgL.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "terraform apply\n",
    "\n",
    "Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the\n",
    "following symbols:\n",
    "  + create\n",
    "\n",
    "Terraform will perform the following actions:\n",
    "\n",
    "  # google_bigquery_dataset.demo_dataset will be created\n",
    "  + resource \"google_bigquery_dataset\" \"demo_dataset\" {\n",
    "      + creation_time              = (known after apply)\n",
    "      + dataset_id                 = \"shamb0_zcamp_2024_hcl_demo_v1_bq_dataset\"\n",
    "      + default_collation          = (known after apply)\n",
    "      + delete_contents_on_destroy = false\n",
    "      + effective_labels           = (known after apply)\n",
    "      + etag                       = (known after apply)\n",
    "      + id                         = (known after apply)\n",
    "      + is_case_insensitive        = (known after apply)\n",
    "      + last_modified_time         = (known after apply)\n",
    "      + location                   = \"US\"\n",
    "      + max_time_travel_hours      = (known after apply)\n",
    "      + project                    = \"shamb0-zoomcamp-lab-01\"\n",
    "      + self_link                  = (known after apply)\n",
    "      + storage_billing_model      = (known after apply)\n",
    "      + terraform_labels           = (known after apply)\n",
    "    }\n",
    "\n",
    "  # google_storage_bucket.demo-bucket will be created\n",
    "  + resource \"google_storage_bucket\" \"demo-bucket\" {\n",
    "      + effective_labels            = (known after apply)\n",
    "      + force_destroy               = true\n",
    "      + id                          = (known after apply)\n",
    "      + location                    = \"US\"\n",
    "      + name                        = \"shamb0_zcamp_2024_hcl_demo_v1_bucket\"\n",
    "      + project                     = (known after apply)\n",
    "      + public_access_prevention    = (known after apply)\n",
    "      + self_link                   = (known after apply)\n",
    "      + storage_class               = \"STANDARD\"\n",
    "      + terraform_labels            = (known after apply)\n",
    "      + uniform_bucket_level_access = (known after apply)\n",
    "      + url                         = (known after apply)\n",
    "\n",
    "      + lifecycle_rule {\n",
    "          + action {\n",
    "              + type = \"AbortIncompleteMultipartUpload\"\n",
    "            }\n",
    "          + condition {\n",
    "              + age                   = 1\n",
    "              + matches_prefix        = []\n",
    "              + matches_storage_class = []\n",
    "              + matches_suffix        = []\n",
    "              + with_state            = (known after apply)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "Plan: 2 to add, 0 to change, 0 to destroy.\n",
    "\n",
    "Do you want to perform these actions?\n",
    "  Terraform will perform the actions described above.\n",
    "  Only 'yes' will be accepted to approve.\n",
    "\n",
    "  Enter a value: yes\n",
    "\n",
    "google_bigquery_dataset.demo_dataset: Creating...\n",
    "google_storage_bucket.demo-bucket: Creating...\n",
    "google_bigquery_dataset.demo_dataset: Creation complete after 1s [id=projects/shamb0-zoomcamp-lab-01/datasets/shamb0_zcamp_2024_hcl_demo_v1_bq_dataset]\n",
    "google_storage_bucket.demo-bucket: Creation complete after 2s [id=shamb0_zcamp_2024_hcl_demo_v1_bucket]\n",
    "\n",
    "Apply complete! Resources: 2 added, 0 changed, 0 destroyed.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "003-01-pydev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
